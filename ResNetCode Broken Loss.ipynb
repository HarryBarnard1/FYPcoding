{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See README file to see where code is sourced from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Sequential, Model,load_model\n",
    "#from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
    "from keras.preprocessing import image\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv2D, MaxPool2D, AveragePooling2D, Input, BatchNormalization, MaxPooling2D, Activation, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import scipy\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining testing and training filepaths gathering emotion labels from file paths.\n",
    "training_path = \"/com.docker.devenvironments.code/fer2013new/trainimgs\"\n",
    "testing_path = \"/com.docker.devenvironments.code/fer2013new/testimgs\"\n",
    "class_names = os.listdir(training_path)\n",
    "class_names_testing = os.listdir(testing_path)\n",
    "\n",
    "#Testing each path making sure all 7 labels are present.\n",
    "print(class_names)\n",
    "print(class_names_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input)\n",
    "testing = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = training.flow_from_directory(\"/com.docker.devenvironments.code/fer2013new/trainimgs\", target_size=(48,48), batch_size = 32, shuffle=True, class_mode='categorical')\n",
    "test_gen = testing.flow_from_directory(\"/com.docker.devenvironments.code/fer2013new/testimgs\", target_size=(48,48), batch_size = 32, shuffle=False, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identity Block\n",
    "\n",
    "def identity(X, f, filters, stage, block):\n",
    "    conv_name_base='res' + str(stage) + block + '_branch'\n",
    "    bn_name_base='bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(1, 1), strides=(1, 1), padding='same', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X = Add()([X, X_shortcut])# SKIP Connection\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Block\n",
    "\n",
    "def convolutional (X, f, filters, stage, block, s=2):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 Block\n",
    "\n",
    "def ResNet50(input_shape=(48,48,3)):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    X = convolutional(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "\n",
    "    X = convolutional(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "    X = identity(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    X = convolutional(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "    X = identity(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    X = X = convolutional(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
    "    X = identity(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(input_shape=(48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer Learning to bypass most training since will take days.\n",
    "\n",
    "newModel = resnet.output\n",
    "newModel = Flatten()(newModel)\n",
    "newModel = Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(newModel)\n",
    "newModel = Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(newModel)\n",
    "newModel = Dense(7,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(newModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Model\n",
    "\n",
    "model = Model(inputs=resnet.input, outputs=newModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet.load_weights(\"/com.docker.devenvironments.code/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in resnet.layers:\n",
    "    #layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping to prevent Overfitting the model.\n",
    "\n",
    "es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max')\n",
    "\n",
    "#H = model.fit_generator(train_gen,validation_data=test_gen,epochs=100,verbose=1,callbacks=[mc,es])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
